{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IxRuYtIZdP2W"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import joblib\n",
        "import numpy as np\n",
        "from flask import Flask, request, jsonify"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "app = Flask(__name__)\n",
        "\n",
        "# 1. Cargar el modelo entrenado al iniciar la app\n",
        "pipeline = joblib.load('modelo_churn.pkl')\n",
        "print(\"Modelo cargado y listo.\")"
      ],
      "metadata": {
        "id": "6thsQvoZingf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "@app.route('/predict', methods=['POST'])\n",
        "def predict():\n",
        "    try:\n",
        "        # Recibir JSON del Backend Java\n",
        "        data = request.json\n",
        "\n",
        "        # Convertir a DataFrame (1 sola fila)\n",
        "        input_df = pd.DataFrame([data])\n",
        "\n",
        "        # --- PASO 1: Predecir ---\n",
        "        prediction = pipeline.predict(input_df)[0] # 0 o 1\n",
        "        probability = pipeline.predict_proba(input_df)[0][1] # Ej: 0.85\n",
        "\n",
        "        # --- PASO 2: Calcular la EXPLICABILIDAD (El \"Por qué\") ---\n",
        "        # Accedemos a las partes internas del pipeline\n",
        "        model = pipeline.named_steps['classifier']\n",
        "        preprocessor = pipeline.named_steps['preprocessor']\n",
        "\n",
        "        # Transformamos los datos del cliente igual que en el entrenamiento\n",
        "        input_transformed = preprocessor.transform(input_df)\n",
        "\n",
        "        # Obtenemos los nombres de las variables transformadas\n",
        "        # (Esto es necesario porque \"Region\" se convierte en \"Region_Asia\", \"Region_Europe\", etc.)\n",
        "        feature_names = (preprocessor.named_transformers_['num'].get_feature_names_out().tolist() +\n",
        "                         preprocessor.named_transformers_['cat'].get_feature_names_out().tolist())\n",
        "\n",
        "        # Obtenemos los coeficientes del modelo (qué peso tiene cada variable)\n",
        "        coefficients = model.coef_[0]\n",
        "\n",
        "        # Calculamos la CONTRIBUCIÓN: Valor * Peso\n",
        "        # Si input_transformed es una matriz dispersa, la convertimos a array\n",
        "        if hasattr(input_transformed, \"toarray\"):\n",
        "            input_transformed = input_transformed.toarray()\n",
        "\n",
        "        contributions = input_transformed[0] * coefficients\n",
        "\n",
        "        # Encontramos cuál variable tuvo el valor más alto\n",
        "        max_index = np.argmax(contributions)\n",
        "        main_factor_name = feature_names[max_index]\n",
        "\n",
        "        # --- PASO 3: Construir Respuesta ---\n",
        "        response = {\n",
        "            \"prediction\": \"Va a Cancelar\" if prediction == 1 else \"Se Queda\",\n",
        "            \"probability\": round(probability, 2), # Ej: 0.85\n",
        "            \"main_factor\": main_factor_name,      # Ej: \"monthly_fee\" o \"region_Europe\"\n",
        "            #\"alert_level\": \"RED\" if probability > 0.7 else \"GREEN\"\n",
        "        }\n",
        "\n",
        "        return jsonify(response)\n",
        "\n",
        "    except Exception as e:\n",
        "        return jsonify({\"error\": str(e)}), 400\n",
        "\n",
        "if __name__ == '__main__':\n",
        "    app.run(port=5000, debug=True)"
      ],
      "metadata": {
        "id": "VLvlD5tgiyBG"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}